---
# === paths & logging ===
base_dir: .
log_level: INFO
# <<--- CLAVE PARA run_demo
log_dir: ./logs/dcrnn_students

# === data ===
data:
  # Apuntar al dataset generado en `data/student_nodes` (train/val/test .npz)
  dataset_dir: data/student_nodes
  # El archivo de adyacencia esperado (puede generarse con create_fully_connected_adj.py)
  graph_pkl_filename: data/student_nodes/adj_mx.pkl
  batch_size: 32
  val_batch_size: 32
  test_batch_size: 32

# === model ===
model:
  # Ajustado para dataset de nodos (student_nodes). Si generaste datos para 10 estudiantes,
  # num_nodes debe ser 10. Si generaste otro número, cámbialo aquí.
  num_nodes: 10
  # El dataset tiene 3 canales (p.ej. x,y,<otro>), conservarlos en input_dim.
  input_dim: 3
  # Predecimos posiciones x,y -> output_dim = 2 (las dos primeras features)
  output_dim: 2
  seq_len: 12                # historia (coincide con el generador de datos usado)
  horizon: 12                # horizonte a predecir

  filter_type: random_walk   # o dual_random_walk (ambas funcionan)
  max_diffusion_step: 2
  num_rnn_layers: 2
  rnn_units: 32
  cl_decay_steps: 2000       # curriculum learning decay
  use_curriculum_learning: true

  # extras comunes en algunos forks:
  l1_decay: 0
  dropout: 0.0               # puedes poner 0.1–0.3 si hay overfitting

# === (algunos supervisores leen estos en top-level; los duplico para compatibilidad) ===
filter_type: random_walk
max_diffusion_step: 2
num_rnn_layers: 2
rnn_units: 32
cl_decay_steps: 2000

# === train ===
train:
  base_lr: 0.001             # (equiv. learning_rate)
  learning_rate: 0.001       # por si tu fork usa este nombre
  epochs: 5                 # puedes subir a 50–100 si T es grande
  patience: 3               # early stopping
  lr_decay_ratio: 0.97
  min_learning_rate: 1.0e-05
  max_grad_norm: 5
  optimizer: adam

  # programar decays por epochs (opcional; si usas base_lr + steps)
  steps: [10, 20, 25]
  test_every_n_epochs: 10

  # otros campos que a veces aparecen en los checkpoints del repo:
  global_step: 0
  epoch: 0
  epsilon: 1.0e-3
  max_to_keep: 20

  # <<--- basename del checkpoint (sin .index / .data-00000-of-00001)
  model_filename: null

# === runtime ===
use_cpu_only: true            # evita intentar GPU con CUDA antigua
