{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "29ecd56e",
   "metadata": {},
   "source": [
    "# Comparación: DCRNN (original) vs DCRNN_predecir_adj_dina (fork modificado)\n",
    "\n",
    "Este notebook documenta los cambios más relevantes que se introdujeron en `DCRNN_predecir_adj_dina` respecto al trabajo original `DCRNN`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29e6cce6",
   "metadata": {},
   "source": [
    "## Resumen ejecutivo\n",
    "\n",
    "- Soporte de adyacencia dinámica (por batch y por timestep) en lugar de requerir una matriz estática precalculada.\n",
    "- Cambios en la arquitectura de evaluación/encoding: bucle de encoding manual para permitir pasar índice temporal y adjacencias por paso de tiempo.\n",
    "- Compatibilidad con instalaciones TF2 (`tf.compat.v1`) mediante un shim y uso de `yaml.safe_load`.\n",
    "- Guardado de matrices de adyacencia generadas en entrenamiento, y modos configurables de alimentación (`last`, `first`, `mean_over_seq`).\n",
    "- Mejor manejo de multi-dimensión de salida en `evaluate` y desescalado por canal.\n",
    "- Varios scripts y artefactos experimentales (carpeta `logs/`, `data/student_nodes/`, `grids/`) añadidos en el fork."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70cab30a",
   "metadata": {},
   "source": [
    "## Estructura y artefactos añadidos\n",
    "\n",
    "En `DCRNN_predecir_adj_dina` se observan directorios y archivos que indican trabajo experimental y checkpoints guardados:\n",
    "- `logs/` con múltiples ejecuciones y subcarpetas `adj_matrices` donde se almacenan `.npz` de adyacencia por batch/timestep.\n",
    "- `data/student_nodes/` con npz de datos de prueba/val/metrics.\n",
    "- `grids/` y directorios de runs con checkpoints (`models-*.data-*`, `config_*.yaml`).\n",
    "- README del fork está vacío; el README original se mantiene en la carpeta `DCRNN` (fuente original)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50f1ffa7",
   "metadata": {},
   "source": [
    "## Cambios en compatibilidad TensorFlow y seguridad\n",
    "\n",
    "1. `dcrnn_train.py` del fork detecta si la versión instalada de TensorFlow es 2.x y, de ser así, importa `tensorflow.compat.v1` y llama a `tf.disable_v2_behavior()` — esto permite ejecutar código escrito para TF1 en entornos con TF2 instalado (útil si el entorno del usuario contiene TF2).\n",
    "2. Se usa `yaml.safe_load(...)` en lugar de `yaml.load(...)` para evitar riesgos de seguridad al leer archivos de configuración."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b2d4a7c",
   "metadata": {},
   "source": [
    "## Soporte de adyacencia dinámica (principales puntos)\n",
    "\n",
    "El fork introduce un sistema para no depender de un `graph_pkl` estático:\n",
    "\n",
    "- Nueva flag en config: `data.dynamic_adj: true` — si está activa, el código NO carga `graph_pkl` y espera recibir adyacencias dinámicas por placeholder.\n",
    "- `data.per_t_dynamic_adj: true` — activa placeholders por timestep con forma `(batch_size, seq_len, N, N)` (una matriz de adyacencia por muestra y por paso de tiempo).\n",
    "- Si `per_t_dynamic_adj` es `false`, se crea un placeholder `(batch_size, N, N)` y se alimenta una adyacencia por muestra en cada batch.\n",
    "- `data.adjacency_feed_mode`: `'last'`, `'first'` o `'mean_over_seq'` — controla qué adyacencia de la secuencia se elige para alimentar cuando no se usa per-timestep.\n",
    "- `data.adjacency_transform`: `'distance'` o `'similarity'` (si `'similarity'` aplica `exp(-d / sigma)`), y `data.adjacency_sigma` controla la transformación.\n",
    "- Las adyacencias se calculan en `DCRNNSupervisor.run_epoch_generator` a partir de las coordenadas en la entrada `x` (se asume que `x[..., :2]` son coordenadas si están presentes), se guardan medias por batch/timestep en `adj_matrices/` y se alimentan al placeholder del modelo."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b874b0c5",
   "metadata": {},
   "source": [
    "## Cambios en `model/dcrnn_model.py` (arquitectura de encoding/decoding)\n",
    "\n",
    "- En el original, el encoding se construía con `encoding_cells = [cell] * num_rnn_layers` y luego `tf.contrib.rnn.static_rnn(encoding_cells, inputs, ...)`. Eso crea referencias al mismo objeto `cell` repetido (posible fuente de bugs).\n",
    "- En el fork, se crean instancias separadas por capa con una lista por comprensión, p.ej. `encoding_cells = [DCGRUCell(...) for _ in range(num_rnn_layers)]`.\n",
    "- El fork implementa un bucle de encoding manual por timestep que mantiene `layer_states` y llama a cada celda con una tupla `(cur_input, time_t)` — esto permite pasar un índice de tiempo y usar adyacencias por-timestep dentro de la celda.\n",
    "- Además el fork permite `adj_mx=None` en la API del modelo; en ese caso crea un placeholder `adj_ph` y lo expone como `adj_placeholder` para ser alimentado en tiempo de ejecución."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a949c187",
   "metadata": {},
   "source": [
    "## Cambios en `model/dcrnn_supervisor.py` (train/eval y cálculo de adyacencia)\n",
    "\n",
    "- `run_epoch_generator` ahora: calcula adyacencias a partir de `x` (posiciones), soporta transformaciones `distance`/`similarity`, maneja excepciones y guarda archivos `.npz` con las adyacencias promedio por batch/timestep.\n",
    "- Al detectar un placeholder de adyacencia (`self._adj_ph`), construye `adj_stack` o `adj_to_feed` según `per_t_dynamic_adj` y `adjacency_feed_mode` y lo inserta en `feed_dict`.\n",
    "- `evaluate` del fork es más robusto para `output_dim > 1`: hace desescalado por canal usando `scaler.mean`/`scaler.std`, calcula métricas por horizonte y devuelve `predictions` y `groundtruth` en su forma no-escalada (por horizonte y por canal).\n",
    "- Se añade la creación del directorio `adj_save_dir` y manejo de excepciones alrededor del guardado de matrices de adyacencia."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
